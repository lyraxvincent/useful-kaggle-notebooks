{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A gentle start to Pytorch\n",
    "\n",
    "![](https://miro.medium.com/max/2400/1*aqNgmfyBIStLrf9k7d9cng.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook aims to give a nice and easy introduction with easy and few steps. It doesn't aim high score! I tried to keep it simple without adding new features. The only and only aim is to a give a very gentle intro to Pytorch world\n",
    "\n",
    "\n",
    "Before that let's give some introduction to Pytorch:\n",
    "\n",
    "PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing. It is primarily developed by Facebook's AI Research lab. It is free and open-source software released under the Modified BSD license. Below is taken from the Pytorch Documentation (you can reach it from https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html\n",
    "\n",
    "You can check more advanced tutorials: \n",
    "\n",
    "- https://pytorch.org/tutorials/\n",
    "\n",
    "Or its github page:\n",
    "\n",
    "- https://github.com/pytorch/pytorch\n",
    "\n",
    "WHAT IS PYTORCH?\n",
    "\n",
    "Itâ€™s a Python-based scientific computing package targeted at two sets of audiences:\n",
    "\n",
    "- A replacement for NumPy to use the power of GPUs\n",
    "- A deep learning research platform that provides maximum flexibility and speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.sciencealert.com/images/articles/processed/titanic-1_600.jpg)\n",
    "\n",
    "For this exercise we will be using the famous **Titanic** Dataset:\n",
    "\n",
    "This is a very famous dataset but if you need an introduction on this, please check this useful links:\n",
    "\n",
    "https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/problem12.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several Cells ara taken from my other notebooks, where I don't use pythorch please check it here:\n",
    "\n",
    "1. https://www.kaggle.com/frtgnn/titanic-survival-classifier\n",
    "\n",
    "2. https://www.kaggle.com/frtgnn/beginner-s-stop-pipeline-introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet & Library Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train = pd.read_csv('../input/titanic/train.csv')\n",
    "df_test  = pd.read_csv('../input/titanic/test.csv')\n",
    "df_sub   = pd.read_csv('../input/titanic/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the dataset ready for the model\n",
    "\n",
    "- let's drop the unnecessary columns\n",
    "- encode the categorical (no details)\n",
    "- impute the necessary columns (again no details)\n",
    "- scale both the train and test data for linear models\n",
    "- split the data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['Name','Ticket','Cabin'],axis=1,inplace=True)\n",
    "df_test.drop( ['Name','Ticket','Cabin'],axis=1,inplace=True)\n",
    "\n",
    "sex = pd.get_dummies(df_train['Sex'],drop_first=True)\n",
    "embark = pd.get_dummies(df_train['Embarked'],drop_first=True)\n",
    "df_train = pd.concat([df_train,sex,embark],axis=1)\n",
    "\n",
    "df_train.drop(['Sex','Embarked'],axis=1,inplace=True)\n",
    "\n",
    "sex = pd.get_dummies(df_test['Sex'],drop_first=True)\n",
    "embark = pd.get_dummies(df_test['Embarked'],drop_first=True)\n",
    "df_test = pd.concat([df_test,sex,embark],axis=1)\n",
    "\n",
    "df_test.drop(['Sex','Embarked'],axis=1,inplace=True)\n",
    "\n",
    "df_train.fillna(df_train.mean(),inplace=True)\n",
    "df_test.fillna(df_test.mean(),inplace=True)\n",
    "\n",
    "Scaler1 = StandardScaler()\n",
    "Scaler2 = StandardScaler()\n",
    "\n",
    "train_columns = df_train.columns\n",
    "test_columns  = df_test.columns\n",
    "\n",
    "df_train = pd.DataFrame(Scaler1.fit_transform(df_train))\n",
    "df_test  = pd.DataFrame(Scaler2.fit_transform(df_test))\n",
    "\n",
    "df_train.columns = train_columns\n",
    "df_test.columns  = test_columns\n",
    "\n",
    "features = df_train.iloc[:,2:].columns.tolist()\n",
    "target   = df_train.loc[:, 'Survived'].name\n",
    "\n",
    "X_train = df_train.iloc[:,2:].values\n",
    "y_train = df_train.loc[:, 'Survived'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=8, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#thank you very much https://www.kaggle.com/mburakergenc/ttianic-minimal-pytorch-mlp\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(8, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Loss Function (Cross Entropy CE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Optimizer (Stochastic Gradient Descent SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (   inf ===> 0.628065). Saving the model...\n",
      "\n",
      "Epoch: 1 \tTrain Loss: 0.6280648373861774 \tTrain Accuracy: 0.0\n",
      "Validation loss decreased (0.628065 ===> 0.571017). Saving the model...\n",
      "Validation loss decreased (0.571017 ===> 0.541278). Saving the model...\n",
      "Validation loss decreased (0.541278 ===> 0.517665). Saving the model...\n",
      "Validation loss decreased (0.517665 ===> 0.495692). Saving the model...\n",
      "Validation loss decreased (0.495692 ===> 0.482916). Saving the model...\n",
      "Validation loss decreased (0.482916 ===> 0.469321). Saving the model...\n",
      "Validation loss decreased (0.469321 ===> 0.461291). Saving the model...\n",
      "Validation loss decreased (0.461291 ===> 0.446276). Saving the model...\n",
      "Validation loss decreased (0.446276 ===> 0.442523). Saving the model...\n",
      "Validation loss decreased (0.442523 ===> 0.438355). Saving the model...\n",
      "Validation loss decreased (0.438355 ===> 0.437279). Saving the model...\n",
      "Validation loss decreased (0.437279 ===> 0.436642). Saving the model...\n",
      "Validation loss decreased (0.436642 ===> 0.428793). Saving the model...\n",
      "Validation loss decreased (0.428793 ===> 0.423462). Saving the model...\n",
      "Validation loss decreased (0.423462 ===> 0.416095). Saving the model...\n",
      "Validation loss decreased (0.416095 ===> 0.415978). Saving the model...\n",
      "Validation loss decreased (0.415978 ===> 0.415961). Saving the model...\n",
      "Validation loss decreased (0.415961 ===> 0.412320). Saving the model...\n",
      "Validation loss decreased (0.412320 ===> 0.411563). Saving the model...\n",
      "Validation loss decreased (0.411563 ===> 0.410000). Saving the model...\n",
      "Validation loss decreased (0.410000 ===> 0.408128). Saving the model...\n",
      "Validation loss decreased (0.408128 ===> 0.407912). Saving the model...\n",
      "Validation loss decreased (0.407912 ===> 0.407499). Saving the model...\n",
      "Validation loss decreased (0.407499 ===> 0.406426). Saving the model...\n",
      "Validation loss decreased (0.406426 ===> 0.404732). Saving the model...\n",
      "Validation loss decreased (0.404732 ===> 0.402680). Saving the model...\n",
      "Validation loss decreased (0.402680 ===> 0.401163). Saving the model...\n",
      "Validation loss decreased (0.401163 ===> 0.401045). Saving the model...\n",
      "Validation loss decreased (0.401045 ===> 0.398563). Saving the model...\n",
      "Validation loss decreased (0.398563 ===> 0.395430). Saving the model...\n",
      "Validation loss decreased (0.395430 ===> 0.391509). Saving the model...\n",
      "Validation loss decreased (0.391509 ===> 0.390163). Saving the model...\n",
      "Validation loss decreased (0.390163 ===> 0.388358). Saving the model...\n",
      "Validation loss decreased (0.388358 ===> 0.386417). Saving the model...\n",
      "Validation loss decreased (0.386417 ===> 0.384408). Saving the model...\n",
      "Validation loss decreased (0.384408 ===> 0.382545). Saving the model...\n",
      "Validation loss decreased (0.382545 ===> 0.379159). Saving the model...\n",
      "Validation loss decreased (0.379159 ===> 0.378802). Saving the model...\n",
      "Validation loss decreased (0.378802 ===> 0.378778). Saving the model...\n",
      "Validation loss decreased (0.378778 ===> 0.377105). Saving the model...\n",
      "Validation loss decreased (0.377105 ===> 0.375945). Saving the model...\n",
      "Validation loss decreased (0.375945 ===> 0.374857). Saving the model...\n",
      "Validation loss decreased (0.374857 ===> 0.373167). Saving the model...\n",
      "Validation loss decreased (0.373167 ===> 0.371774). Saving the model...\n",
      "Validation loss decreased (0.371774 ===> 0.366424). Saving the model...\n",
      "Validation loss decreased (0.366424 ===> 0.365755). Saving the model...\n",
      "Validation loss decreased (0.365755 ===> 0.365006). Saving the model...\n",
      "Validation loss decreased (0.365006 ===> 0.363772). Saving the model...\n",
      "Validation loss decreased (0.363772 ===> 0.363733). Saving the model...\n",
      "\n",
      "Epoch: 201 \tTrain Loss: 0.36764609585152636 \tTrain Accuracy: 0.0\n",
      "Validation loss decreased (0.363733 ===> 0.363211). Saving the model...\n",
      "Validation loss decreased (0.363211 ===> 0.359882). Saving the model...\n",
      "Validation loss decreased (0.359882 ===> 0.359585). Saving the model...\n",
      "Validation loss decreased (0.359585 ===> 0.358834). Saving the model...\n",
      "Validation loss decreased (0.358834 ===> 0.355805). Saving the model...\n",
      "Validation loss decreased (0.355805 ===> 0.354886). Saving the model...\n",
      "Validation loss decreased (0.354886 ===> 0.351723). Saving the model...\n",
      "Validation loss decreased (0.351723 ===> 0.349084). Saving the model...\n",
      "Validation loss decreased (0.349084 ===> 0.345382). Saving the model...\n",
      "Validation loss decreased (0.345382 ===> 0.344643). Saving the model...\n",
      "\n",
      "Epoch: 401 \tTrain Loss: 0.35968057746850235 \tTrain Accuracy: 0.0\n",
      "Validation loss decreased (0.344643 ===> 0.341058). Saving the model...\n",
      "Validation loss decreased (0.341058 ===> 0.337267). Saving the model...\n",
      "Training Ended! \n"
     ]
    }
   ],
   "source": [
    "#thank you very much https://www.kaggle.com/mburakergenc/ttianic-minimal-pytorch-mlp\n",
    "\n",
    "batch_size = 64\n",
    "n_epochs = 500\n",
    "batch_no = len(X_train) // batch_size\n",
    "\n",
    "train_loss = 0\n",
    "train_loss_min = np.Inf\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(batch_no):\n",
    "        start = i*batch_size\n",
    "        end = start+batch_size\n",
    "        x_var = Variable(torch.FloatTensor(X_train[start:end]))\n",
    "        y_var = Variable(torch.LongTensor(y_train[start:end])) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_var)\n",
    "        loss = criterion(output,y_var)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        values, labels = torch.max(output, 1)\n",
    "        num_right = np.sum(labels.data.numpy() == y_train[start:end])\n",
    "        train_loss += loss.item()*batch_size\n",
    "    \n",
    "    train_loss = train_loss / len(X_train)\n",
    "    if train_loss <= train_loss_min:\n",
    "        print(\"Validation loss decreased ({:6f} ===> {:6f}). Saving the model...\".format(train_loss_min,train_loss))\n",
    "        torch.save(model.state_dict(), \"model.pt\")\n",
    "        train_loss_min = train_loss\n",
    "    \n",
    "    if epoch % 200 == 0:\n",
    "        print('')\n",
    "        print(\"Epoch: {} \\tTrain Loss: {} \\tTrain Accuracy: {}\".format(epoch+1, train_loss,num_right / len(y_train[start:end]) ))\n",
    "print('Training Ended! ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.iloc[:,1:].values\n",
    "X_test_var = Variable(torch.FloatTensor(X_test), requires_grad=False) \n",
    "with torch.no_grad():\n",
    "    test_result = model(X_test_var)\n",
    "values, labels = torch.max(test_result, 1)\n",
    "survived = labels.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId': df_sub['PassengerId'], 'Survived': survived})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have found 3 nice courses online, checked them out and they are really nice!\n",
    "\n",
    "- https://www.udemy.com/course/pytorch-for-deep-learning-with-python-bootcamp/?ranMID=39197&ranEAID=vedj0cWlu2Y&ranSiteID=vedj0cWlu2Y-FiBKCfRWMo8DOXuV0uYFLg&LSNPUBID=vedj0cWlu2Y\n",
    "\n",
    "- https://www.coursera.org/learn/deep-neural-networks-with-pytorch?ranMID=40328&ranEAID=vedj0cWlu2Y&ranSiteID=vedj0cWlu2Y-TFDEo8s4j9f2CxC59L3_8w&siteID=vedj0cWlu2Y-TFDEo8s4j9f2CxC59L3_8w&utm_content=10&utm_medium=partners&utm_source=linkshare&utm_campaign=vedj0cWlu2Y\n",
    "\n",
    "- https://www.udacity.com/course/deep-learning-pytorch--ud188?cjevent=becd1b75759d11ea83f301a10a24060d\n",
    "(this one's free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## thank you!\n",
    "## I'll try to add more info and make it better asap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
